{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9440\n",
      "ACC: 0.8628\n",
      "Recall: 0.8741\n",
      "F1-score: 0.8634\n",
      "Precesion: 0.8530\n",
      "Table: [[1716  299]\n",
      " [ 250 1735]]\n",
      "AUC: 0.9558\n",
      "ACC: 0.8832\n",
      "Recall: 0.8988\n",
      "F1-score: 0.8863\n",
      "Precesion: 0.8742\n",
      "Table: [[1712  262]\n",
      " [ 205 1821]]\n",
      "AUC: 0.9532\n",
      "ACC: 0.8808\n",
      "Recall: 0.9071\n",
      "F1-score: 0.8833\n",
      "Precesion: 0.8608\n",
      "Table: [[1717  292]\n",
      " [ 185 1806]]\n",
      "AUC: 0.9517\n",
      "ACC: 0.8725\n",
      "Recall: 0.8911\n",
      "F1-score: 0.8739\n",
      "Precesion: 0.8574\n",
      "Table: [[1723  294]\n",
      " [ 216 1767]]\n",
      "AUC: 0.9535\n",
      "ACC: 0.8772\n",
      "Recall: 0.8983\n",
      "F1-score: 0.8806\n",
      "Precesion: 0.8635\n",
      "Table: [[1699  286]\n",
      " [ 205 1810]]\n",
      "avg acc: 0.8753\n",
      "avg precision: 0.8618\n",
      "avg recall: 0.8939\n",
      "avg f1_score: 0.8775\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0c398be2ea66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature importances\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"LightGBM.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(filename)s : %(funcName)s : %(message)s', level=logging.ERROR)\n",
    "    basepath = \"feature/feature3/\"\n",
    "    generatepath = \"res/res3/\"\n",
    "    figpath = \"fig/fig3/\"\n",
    "    label = 3\n",
    "    method = \"ALL\" # or TBF or ALL(APF+TBF)\n",
    "    N = 11 # 11 means 1~10 0 means APF, don't need N-Gram\n",
    "    \n",
    "    sf1 = pd.read_csv(basepath + \"1gramfeature_short.csv\")\n",
    "    sf2 = pd.read_csv(basepath + \"2gramfeature_short.csv\")\n",
    "    sf3 = pd.read_csv(basepath + \"3gramfeature_short.csv\")\n",
    "    sf4 = pd.read_csv(basepath + \"4gramfeature_short.csv\")\n",
    "    sf5 = pd.read_csv(basepath + \"5gramfeature_short.csv\")\n",
    "    sf6 = pd.read_csv(basepath + \"6gramfeature_short.csv\")\n",
    "    sf7 = pd.read_csv(basepath + \"7gramfeature_short.csv\")\n",
    "    sf8 = pd.read_csv(basepath + \"8gramfeature_short.csv\")\n",
    "    sf9 = pd.read_csv(basepath + \"9gramfeature_short.csv\")\n",
    "    sf10 = pd.read_csv(basepath + \"10gramfeature_short.csv\")  \n",
    "    \n",
    "    subtrainLabel = pd.read_csv('subtrainLabels' + str(label) + '.csv')\n",
    "    if(method == \"APF\"):\n",
    "        sf = sf1.drop(sf1.columns[1:-15], axis=1)\n",
    "    elif(method == \"TBF\"):\n",
    "        if(N < 11):\n",
    "            sf = pd.read_csv(basepath + str(N) + \"gramfeature_short.csv\")\n",
    "            sf = sf[sf.columns[0:-15]]\n",
    "        elif(N == 11):\n",
    "            sf = pd.concat([sf1[sf1.columns[0:-15]],sf2[sf2.columns[1:-15]],sf3[sf3.columns[1:-15]],sf4[sf4.columns[1:-15]],sf5[sf5.columns[1:-15]],sf6[sf6.columns[1:-15]],sf7[sf7.columns[1:-15]],sf8[sf8.columns[1:-15]],sf9[sf9.columns[1:-15]],sf10[sf10.columns[1:-15]]],axis=1)\n",
    "    elif(method == \"ALL\"):\n",
    "        if(N < 11):\n",
    "            sf = pd.read_csv(basepath + str(N) + \"gramfeature_short.csv\")\n",
    "        elif(N == 11):\n",
    "            sf = pd.concat([sf1,sf2[sf2.columns[1:-15]],sf3[sf3.columns[1:-15]],sf4[sf4.columns[1:-15]],sf5[sf5.columns[1:-15]],sf6[sf6.columns[1:-15]],sf7[sf7.columns[1:-15]],sf8[sf8.columns[1:-15]],sf9[sf9.columns[1:-15]],sf10[sf10.columns[1:-15]]],axis=1)\n",
    "\n",
    "    subtrain = pd.merge(subtrainLabel, sf, on='Id')\n",
    "    label = subtrain.Class\n",
    "    x = subtrain.drop([\"Class\",\"Id\"],axis=1)\n",
    "    feature = x.columns\n",
    "    data = x.values\n",
    "    \n",
    "    k = 10\n",
    "    n_splits = 5\n",
    "    res = 0\n",
    "    res_recall = 0.0\n",
    "    res_precision = 0.0\n",
    "    f1_score = 0.0\n",
    "    \n",
    "    # # 测试集和训练集\n",
    "    kf = KFold(n_splits,shuffle=False)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_x, test_x = data[train_index], data[test_index]\n",
    "        train_y, test_y = label[train_index], label[test_index]\n",
    "        dtrain=xgb.DMatrix(train_x,label=train_y)\n",
    "        dtest=xgb.DMatrix(test_x)\n",
    "\n",
    "#         params={'booster':'gbtree',\n",
    "#                 'objective': 'binary:logistic',\n",
    "#                 'eval_metric': 'auc',\n",
    "#                 'max_depth':10,\n",
    "#                 'lambda':300,\n",
    "#                 'gamma':0.2,\n",
    "#                 'subsample':1.0,\n",
    "#                 'colsample_bytree':0.2,\n",
    "#                 'scale_pos_weight':0.1,\n",
    "#                 'min_child_weight':5,\n",
    "#                 'eta': 0.025,\n",
    "#                 'seed':0,\n",
    "#                 'nthread':8,\n",
    "#                 'silent':1}\n",
    "#         watchlist = [(dtrain,'train')]\n",
    "#         bst=xgb.train(params,dtrain,num_boost_round=100,evals=watchlist)\n",
    "#         ypred=bst.predict(dtest)\n",
    "        other_params = {'learning_rate': 0.1, 'n_estimators': 490, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,\n",
    "                    'subsample': 0.9, 'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 1, 'reg_lambda': 2}\n",
    "\n",
    "        bst = xgb.XGBRegressor(**other_params)\n",
    "        bst.fit(train_x, train_y)\n",
    "        ypred=bst.predict(test_x)\n",
    "        y_pred = (ypred >= 0.5)*1\n",
    "\n",
    "        print('AUC: %.4f' % metrics.roc_auc_score(test_y,ypred))\n",
    "        print('ACC: %.4f' % metrics.accuracy_score(test_y,y_pred))\n",
    "        print('Recall: %.4f' % metrics.recall_score(test_y,y_pred))\n",
    "        print('F1-score: %.4f' %metrics.f1_score(test_y,y_pred))\n",
    "        print('Precesion: %.4f' %metrics.precision_score(test_y,y_pred))\n",
    "        print('Table: {}'.format(metrics.confusion_matrix(test_y,y_pred)))\n",
    "        matrix = metrics.confusion_matrix(test_y,y_pred)\n",
    "        res+=metrics.accuracy_score(test_y,y_pred)\n",
    "        res_recall+= metrics.recall_score(test_y,y_pred)\n",
    "        res_precision+= metrics.precision_score(test_y,y_pred)\n",
    "        f1_score +=  metrics.f1_score(test_y,y_pred)\n",
    "\n",
    "    res/=5\n",
    "    res_recall/=5\n",
    "    res_precision/=5\n",
    "    f1_score/=5\n",
    "    print(\"avg acc: %.4f\" %res)\n",
    "    print(\"avg precision: %.4f\" %res_precision)\n",
    "    print(\"avg recall: %.4f\" %res_recall)\n",
    "    print(\"avg f1_score: %.4f\" %f1_score)\n",
    "    res = {'acc':[res], 'precision':[res_precision], 'recall':[res_recall],'f1-score':[f1_score]}\n",
    "    df = pd.DataFrame(res)\n",
    "    df.to_csv(generatepath + method + str(N) + \"XGBoost.csv\",index=False)\n",
    "    \n",
    "    plt.figure(figsize=(18,9))\n",
    "    lgb.plot_importance(model, max_num_features=30)\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.savefig(figpath + method + str(N) + \"LightGBM.png\")\n",
    "    plt.show()\n",
    "\n",
    "    feature_importance = pd.DataFrame({'feature_name':list(feature),'importance':list(model.feature_importance())} )\n",
    "    feature_importance.to_csv(figpath + method + str(N) + 'LightGBM feature_importance.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
